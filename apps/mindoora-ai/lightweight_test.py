#!/usr/bin/env python3
"""
Lightweight test to verify models can be loaded
"""

import os
from transformers import AutoTokenizer, AutoConfig

def test_model_loading(model_path, model_name):
    """Test if model can be loaded without running inference"""
    print(f"\nğŸ§ª Testing {model_name}...")
    print(f"ğŸ“ Path: {model_path}")
    
    try:
        # Test config loading
        print("ğŸ“‹ Loading model config...")
        config = AutoConfig.from_pretrained(model_path, local_files_only=True)
        print(f"  âœ… Config loaded: {config.model_type}")
        
        # Test tokenizer loading
        print("ğŸ”¤ Loading tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
        print(f"  âœ… Tokenizer loaded: vocab_size={tokenizer.vocab_size}")
        
        # Test basic tokenization
        test_text = "Hello world"
        tokens = tokenizer.encode(test_text)
        decoded = tokenizer.decode(tokens)
        print(f"  âœ… Tokenization test: '{test_text}' -> {len(tokens)} tokens -> '{decoded}'")
        
        print(f"  ğŸ‰ {model_name} is working correctly!")
        return True
        
    except Exception as e:
        print(f"  âŒ Error testing {model_name}: {str(e)}")
        return False

def main():
    """Test all models"""
    print("ğŸš€ Lightweight Model Testing")
    print("=" * 50)
    
    models_to_test = [
        ("models/distilgpt2", "DistilGPT-2"),
        ("models/gpt2", "GPT-2"),
        ("models/flan-t5-small", "FLAN-T5-Small"),
    ]
    
    results = {}
    for model_path, model_name in models_to_test:
        if os.path.exists(model_path):
            results[model_name] = test_model_loading(model_path, model_name)
        else:
            print(f"\nâŒ {model_name} not found at {model_path}")
            results[model_name] = False
    
    # Summary
    print("\n" + "=" * 50)
    print("ğŸ“Š Test Results:")
    
    passed = sum(1 for result in results.values() if result)
    total = len(results)
    
    for model_name, result in results.items():
        status = "âœ… WORKING" if result else "âŒ FAILED"
        print(f"  {model_name}: {status}")
    
    print(f"\nğŸ¯ Overall: {passed}/{total} models working")
    
    if passed == total:
        print("ğŸ‰ All models are functional!")
    else:
        print("âš ï¸  Some models have issues")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
